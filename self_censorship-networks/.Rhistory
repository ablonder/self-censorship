library(coin)
install.packages
install.packages("coin")
install.packages("mvtnorm")
install.packages("coin")
install.packages("coin")
cite(coin)
library(coin)
cite(coin)
citation(coin)
citation("coin")
MidtermGrades <- read.csv("~/Documents/GradSchool/TA/2022Spring/MidtermGrades.csv")
View(MidtermGrades)
?geom_hist
library(ggplot2)
?geom_hist
ggplot2(MidtermGrades, aes(x = Total, color = version)) + geom_histogram()
ggplot(MidtermGrades, aes(x = Total, color = version)) + geom_histogram()
ggplot(MidtermGrades, aes(x = Total, fill = version)) + geom_histogram()
dev.off()
--version
version
MidtermGrades <- read.csv("~/Documents/GradSchool/TA/2022Spring/MidtermGrades.csv")
library(ggplot2)
ggplot(MidtermGrades, aes(x = Total, fill = version)) + geom_histogram()
ggplot(MidtermGrades, aes(x = Total, fill = as.factor(version))) + geom_histogram()
ggplot(MidtermGrades, aes(x = Total, color = as.factor(version))) + geom_histogram(fill = "white")
ggplot(MidtermGrades, aes(x = Total, color = as.factor(version))) + geom_histogram(fill = "white", alpha = .5)
ggplot(MidtermGrades, aes(x = Total, color = as.factor(version))) + geom_histogram(fill = "white", alpha = .2)
ggplot(MidtermGrades, aes(x = Total, color = as.factor(version))) + geom_histogram(fill = "white", position = "dodge")
ggplot(MidtermGrades, aes(x = Total, color = as.factor(version))) + geom_histogram(fill = "white", alpha = .1, bins = 20)
ggplot(MidtermGrades, aes(x = Total, color = as.factor(version))) + geom_histogram(fill = "white", position = "dodge", bins = 20)
ggplot(MidtermGrades, aes(x = Total, fill = as.factor(version))) + geom_histogram(position = "dodge", bins = 20)
MidtermGrades$version = as.factor(MidtermGrades$version)
ggplot(MidtermGrades, aes(x = Total, fill = version)) + geom_histogram(position = "dodge", bins = 20)
summarise(group_by(MidtermGrades, version), median = median(Total))
library(dplyr)
summarise(group_by(MidtermGrades, version), median = median(Total))
# function to get social networks from data and do analyses (doing this the right way like a real programmer)
library(tidyr)
library(dplyr)
library(ggplot2)
library(igraph)
# takes in a list of filenames, parameters to loop through, and a few analysis options:
## summeasures - returns a table with the network's density, diameter, mean shortest distance, mean and standard deviation
### of degree, maximum modularity, number of cross-cluster edges, and mean and standard deviation of cluster size
## visualize - creates and saves visualizations of the networks
## degreedist - creates and saves histograms of the degree distribution
## components - creates and saves plot of component size distribution
## weighted - determines whether the "info" column in the edge list is used as weights for the network
# TODO - create an option to color the nodes by some parameter
analyzeNets = function(fnames, params, summeasures = F, visualize = F, degreedist = F, components = F, weighted = F){
# if summeasures, start by creating a table to hold the results (the column names don't work so I'll just add them later)
if(summeasures){
res = data.frame()
}
# then loop through each of the file names
for(f in fnames){
# the filenames provided should actually just be the beginning of the names of the edge list and agent results files
edges = filter(read.table(paste0(f, "edgelist.txt"), comment.char = "%", header = T, sep = ","), Timestep > 0)
nodes = filter(read.table(paste0(f, "agentresults.txt"), comment.char = "%",  header = T, sep = ","), Timestep > 0)
# once the data has been read in, we can create condition codes from the provided parameters for looping through
edges$condcode = ""
nodes$condcode = ""
for(p in params){
# only add it if the parameter is actually there
if(p %in% colnames(edges)){
edges$condcode = paste(edges$condcode, p, edges[, p])
nodes$condcode = paste(nodes$condcode, p, nodes[, p])
}
}
# now we can loop through all the conditions, create the networks, and do the desired analyses
for(cond in unique(edges$condcode)){
# also loop through all the replicates for each condition (by random seed)
for(s in unique(edges[edges$condcode == cond, "Seed"])){
# grab the current part of the data
e = edges[edges$Seed == s & edges$condcode == cond, c("from","to", "info")]
v = nodes[nodes$Seed == s & nodes$condcode == cond, c("Agent")]
# load it in as a network (to make sure all vertices are accounted for, I'll have to do some combining)
net = graph_from_data_frame(e, vertices = unique(c(unique(e$from), unique(e$to), unique(v))))
# if we want to consider edge weights, igraph expects those in an attribute named "weight"
if(weighted){
E(net)$weight = E(net)$info
}
# if we're doing summary measures, those will be calculated now
if(summeasures){
# for the results, start with the seed and condition code (including the filename)
r = c(s, paste(f, cond))
# then the actual parameters
for(p in params){
r = c(r, ifelse(p %in% colnames(edges), unique(edges[edges$condcode == cond, p]), NA))
}
# simple metrics first: density, diameter, and mean distance
r = c(r, edge_density(net), diameter(net), mean_distance(net))
# average (and standard deviation in) degree
deg = degree(net, mode = "all")
r = c(r, mean(deg), sd(deg))
# number of components and average (and standard deviation in) size
comp = components(net)
r = c(r, comp$no, mean(comp$csize), sd(comp$csize))
# now for a few more complicated metrics of community structure (for which I need an undirected network)
clusters = cluster_fast_greedy(as.undirected(net, mode="collapse"))
# modularity, proportion of possible edges that cross communities, cluster size (mean and standard deviation)
r = c(r, modularity(clusters), sum(crossing(clusters, net))/(vcount(net)*(vcount(net)-1)/2),
mean(sizes(clusters)), sd(sizes(clusters)))
# add it all to the results table
res = rbind(res, r)
}
# if we're visualizing the network, do that and save it in a file (in a separate folder)
if(visualize){
jpeg(filename = paste0("graphs/", f, cond, "Seed", s, "net.jpeg"))
plot(net, vertex.label = NA, edge.arrow.size = .1, vertex.size = 3, layout = layout.fruchterman.reingold, rescale = T)
dev.off()
}
# if we're plotting degree distributions, do that and save them too
if(degreedist){
jpeg(filename = paste0("graphs/", f, cond, "Seed", s, "degdist.jpeg"))
hist(degree(net, mode = "all"))
dev.off()
}
# same for plotting the component size distribution
if(components){
jpeg(filename = paste0("graphs/", f, cond, "Seed", s, "components.jpeg"))
hist(components(net)$csize)
dev.off()
}
}
}
}
# everything should be all done unless it's supposed to return a dataframe of results
if(summeasures){
# in that case, we need to give the results proper column names
colnames(res) = c("seed", "condition", params, "density", "diameter", "meandist", "degree", "sddegree", "components",
"componentsize", "sdcomponentsize", "modularity", "crosscluster", "clustersize", "sdclustersize")
# and convert everything back to numeric
res[,-2] = sapply(res[,-2], as.numeric)
# then return it
return(res)
}
}
setwd("Documents/Research/self-censorship/self_censorship-networks")
# function to get social networks from data and do analyses (doing this the right way like a real programmer)
library(tidyr)
library(dplyr)
library(ggplot2)
library(igraph)
# takes in a list of filenames, parameters to loop through, and a few analysis options:
## summeasures - returns a table with the network's density, diameter, mean shortest distance, mean and standard deviation
### of degree, maximum modularity, number of cross-cluster edges, and mean and standard deviation of cluster size
## visualize - creates and saves visualizations of the networks
## degreedist - creates and saves histograms of the degree distribution
## components - creates and saves plot of component size distribution
## weighted - determines whether the "info" column in the edge list is used as weights for the network
# TODO - create an option to color the nodes by some parameter
analyzeNets = function(fnames, params = c(), summeasures = F, visualize = F, degreedist = F, components = F, weighted = F){
# if summeasures, start by creating a table to hold the results (the column names don't work so I'll just add them later)
if(summeasures){
res = data.frame()
}
# then loop through each of the file names
for(f in fnames){
# the filenames provided should actually just be the beginning of the names of the edge list and agent results files
edges = filter(read.table(paste0(f, "edgelist.txt"), comment.char = "%", header = T, sep = ","), Timestep > 0)
nodes = filter(read.table(paste0(f, "agentresults.txt"), comment.char = "%",  header = T, sep = ","), Timestep > 0)
# once the data has been read in, we can create condition codes from the provided parameters for looping through
edges$condcode = ""
nodes$condcode = ""
for(p in params){
# only add it if the parameter is actually there
if(p %in% colnames(edges)){
edges$condcode = paste(edges$condcode, p, edges[, p])
nodes$condcode = paste(nodes$condcode, p, nodes[, p])
}
}
# now we can loop through all the conditions, create the networks, and do the desired analyses
for(cond in unique(edges$condcode)){
# also loop through all the replicates for each condition (by random seed)
for(s in unique(edges[edges$condcode == cond, "Seed"])){
# grab the current part of the data
e = edges[edges$Seed == s & edges$condcode == cond, c("from","to", "info")]
v = nodes[nodes$Seed == s & nodes$condcode == cond, c("Agent")]
# load it in as a network (to make sure all vertices are accounted for, I'll have to do some combining)
net = graph_from_data_frame(e, vertices = unique(c(unique(e$from), unique(e$to), unique(v))))
# if we want to consider edge weights, igraph expects those in an attribute named "weight"
if(weighted){
E(net)$weight = E(net)$info
}
# if we're doing summary measures, those will be calculated now
if(summeasures){
# for the results, start with the seed and condition code (including the filename)
r = c(s, paste(f, cond))
# then the actual parameters
for(p in params){
r = c(r, ifelse(p %in% colnames(edges), unique(edges[edges$condcode == cond, p]), NA))
}
# simple metrics first: density, diameter, and mean distance
r = c(r, edge_density(net), diameter(net), mean_distance(net))
# average (and standard deviation in) degree
deg = degree(net, mode = "all")
r = c(r, mean(deg), sd(deg))
# number of components and average (and standard deviation in) size
comp = components(net)
r = c(r, comp$no, mean(comp$csize), sd(comp$csize))
# now for a few more complicated metrics of community structure (for which I need an undirected network)
clusters = cluster_fast_greedy(as.undirected(net, mode="collapse"))
# modularity, proportion of possible edges that cross communities, cluster size (mean and standard deviation)
r = c(r, modularity(clusters), sum(crossing(clusters, net))/(vcount(net)*(vcount(net)-1)/2),
mean(sizes(clusters)), sd(sizes(clusters)))
# add it all to the results table
res = rbind(res, r)
}
# if we're visualizing the network, do that and save it in a file (in a separate folder)
if(visualize){
jpeg(filename = paste0("graphs/", f, cond, "Seed", s, "net.jpeg"))
plot(net, vertex.label = NA, edge.arrow.size = .1, vertex.size = 3, layout = layout.fruchterman.reingold, rescale = T)
dev.off()
}
# if we're plotting degree distributions, do that and save them too
if(degreedist){
jpeg(filename = paste0("graphs/", f, cond, "Seed", s, "degdist.jpeg"))
hist(degree(net, mode = "all"))
dev.off()
}
# same for plotting the component size distribution
if(components){
jpeg(filename = paste0("graphs/", f, cond, "Seed", s, "components.jpeg"))
hist(components(net)$csize)
dev.off()
}
}
}
}
# everything should be all done unless it's supposed to return a dataframe of results
if(summeasures){
# in that case, we need to give the results proper column names
colnames(res) = c("seed", "condition", params, "density", "diameter", "meandist", "degree", "sddegree", "components",
"componentsize", "sdcomponentsize", "modularity", "crosscluster", "clustersize", "sdclustersize")
# and convert everything back to numeric
res[,-2] = sapply(res[,-2], as.numeric)
# then return it
return(res)
}
}
analyzeNets(test, visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
analyzeNets(c("test"), visualize = T)
